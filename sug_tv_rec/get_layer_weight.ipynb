{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "uuid": "29898d82-0e0d-456b-8b72-4544fa8174bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep dense 维度：32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for WideDeep:\n\tsize mismatch for deeptext.embedding.weight: copying a param with shape torch.Size([142710, 32]) from checkpoint, the shape in current model is torch.Size([180000, 32]).\n\tsize mismatch for prefix_embedding.weight: copying a param with shape torch.Size([85175, 32]) from checkpoint, the shape in current model is torch.Size([105000, 32]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5722f73ec9bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mwide_deep_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWideDeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepdense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeepdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeeptext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mwide_deep_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log/05-09_14.14/sug_saved_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwide_deep_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for WideDeep:\n\tsize mismatch for deeptext.embedding.weight: copying a param with shape torch.Size([142710, 32]) from checkpoint, the shape in current model is torch.Size([180000, 32]).\n\tsize mismatch for prefix_embedding.weight: copying a param with shape torch.Size([85175, 32]) from checkpoint, the shape in current model is torch.Size([105000, 32])."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from models.DeepDense import DeepDense\n",
    "from models.TextLSTM import TextLSTM\n",
    "from models.DNNAttr import DNNAttr\n",
    "from models.Wide import Wide\n",
    "\n",
    "from models.WideDeep import WideDeep\n",
    "from optim.Initializer import KaimingNormal, XavierNormal\n",
    "from optim.radam import RAdam\n",
    "from pandas import DataFrame\n",
    "from preprocessing.Preprocessor import WidePreprocessor, DeepPreprocessor, DeepTextPreprocessor, MultiDeepTextPreprocessor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, os\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import torch\n",
    "\n",
    "\n",
    "wide = Wide(wide_dim=17, output_dim=1)\n",
    "\n",
    "# init deep_dense model\n",
    "deep_column_idx = dict()\n",
    "deep_column_idx['family_pred_gender'] = 0\n",
    "deep_column_idx['family_pred_age_level'] = 1\n",
    "deep_column_idx['category'] = 2\n",
    "deep_column_idx['ott_uv_norm'] = 3\n",
    "deep_column_idx['category_prefer'] = 4\n",
    "emb_col_val_dim_tuple = []\n",
    "emb_col_val_dim_tuple.append(('family_pred_gender', 4, 8))\n",
    "emb_col_val_dim_tuple.append(('family_pred_age_level', 1024, 12))\n",
    "emb_col_val_dim_tuple.append(('category', 28, 8))\n",
    "deepdense = DeepDense(hidden_layers=[32], dropout=[0.2], deep_column_idx=deep_column_idx, embed_input=emb_col_val_dim_tuple, continuous_cols=['ott_uv_norm', 'category_prefer'])\n",
    "\n",
    "# init transformer model\n",
    "transformer = DNNAttr()\n",
    "\n",
    "wide_deep_model = WideDeep(wide=wide, deepdense=deepdense, deeptext=transformer, head_layers=[128])\n",
    "wide_deep_model.load_state_dict(torch.load('log/05-09_14.14/sug_saved_model.pt'))\n",
    "\n",
    "for name, param in wide_deep_model.named_parameters():\n",
    "    print(name, '        ', param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "085404cb-d5c3-4b42-8b3e-f705894dcef2"
   },
   "outputs": [],
   "source": [
    "wide_linear_weight=''\n",
    "wide_linear_bias=''\n",
    "emb_layer_category=''\n",
    "emb_layer_family_pred_age_level=''\n",
    "emb_layer_family_pred_gender=''\n",
    "dense_layer_0_w=''\n",
    "dense_layer_0_bias=''\n",
    "dense_layer_1_w=''\n",
    "dense_layer_1_bias=''\n",
    "query_embedding=''\n",
    "query_embedding_fc_w=''\n",
    "query_embedding_fc_bias=''\n",
    "prefix_embedding=''\n",
    "head_layer_0_w=''\n",
    "head_layer_0_bias=''\n",
    "head_layer_1_w=''\n",
    "head_layer_1_bias=''\n",
    "head_out_w=''\n",
    "head_out_bias=''\n",
    "for name, param in wide_deep_model.named_parameters():\n",
    "    \n",
    "    if 'wide.wide_linear.weight' in name:\n",
    "        wide_linear_weight = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    if 'wide.wide_linear.bias' in name:\n",
    "        wide_linear_bias = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    # deepdense\n",
    "    if 'deepdense.embed_layers_dic.emb_layer_category.weight' in name:\n",
    "        emb_layer_category = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    if 'deepdense.embed_layers_dic.emb_layer_family_pred_age_level.weight' in name:\n",
    "        emb_layer_family_pred_age_level = np.round(param.detach().numpy(), 3)\n",
    "        \n",
    "    if 'deepdense.embed_layers_dic.emb_layer_family_pred_gender.weight' in name:\n",
    "        emb_layer_family_pred_gender = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    if 'deepdense.dense_sequential.dense_layer_0.0.weight' in name:\n",
    "        dense_layer_0_w = np.round(param.detach().numpy(), 3)\n",
    "    if 'deepdense.dense_sequential.dense_layer_0.0.bias' in name:\n",
    "        dense_layer_0_bias = np.round(param.detach().numpy(), 3)\n",
    "    if 'deepdense.dense_sequential.dense_layer_1.0.weight' in name:\n",
    "        dense_layer_1_w = np.round(param.detach().numpy(), 3)\n",
    "    if 'deepdense.dense_sequential.dense_layer_1.0.bias' in name:\n",
    "        dense_layer_1_bias = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    \n",
    "    # text\n",
    "    if 'deeptext.embedding.weight' in name:\n",
    "        query_embedding = np.round(param.detach().numpy(), 3)\n",
    "    if 'deeptext.fc.weight' in name:\n",
    "        query_embedding_fc_w = np.round(param.detach().numpy(), 3)\n",
    "    if 'deeptext.fc.bias' in name:\n",
    "        query_embedding_fc_bias = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    # prefix\n",
    "    if 'prefix_embedding.weight' in name:\n",
    "        prefix_embedding = np.round(param.detach().numpy(), 3)\n",
    "    if 'deephead.head_layer_0.0.weight' in name:\n",
    "        head_layer_0_w = np.round(param.detach().numpy(), 3)\n",
    "    if 'deephead.head_layer_0.0.bias' in name:\n",
    "        head_layer_0_bias = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    if 'deephead.head_layer_1.0.weight' in name:\n",
    "        head_layer_1_w = np.round(param.detach().numpy(), 3)\n",
    "    if 'deephead.head_layer_1.0.bias' in name:\n",
    "        head_layer_1_bias = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    if 'deephead.head_out.weight' in name:\n",
    "        head_out_w = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "    if 'deephead.head_out.bias' in name:\n",
    "        head_out_bias = np.round(param.detach().numpy(), 3)\n",
    "    \n",
    "np.savez(\"param.npz\", wide_linear_weight=wide_linear_weight,\n",
    "                        wide_linear_bias=wide_linear_bias,\n",
    "                        emb_layer_category=emb_layer_category,\n",
    "                        emb_layer_family_pred_age_level=emb_layer_family_pred_age_level,\n",
    "                        emb_layer_family_pred_gender=emb_layer_family_pred_gender,\n",
    "                        dense_layer_0_w=dense_layer_0_w,\n",
    "                        dense_layer_0_bias=dense_layer_0_bias,\n",
    "                        dense_layer_1_w=dense_layer_1_w,\n",
    "                        dense_layer_1_bias=dense_layer_1_bias,\n",
    "                        query_embedding=query_embedding,\n",
    "                        query_embedding_fc_w=query_embedding_fc_w,\n",
    "                        query_embedding_fc_bias=query_embedding_fc_bias,\n",
    "                        prefix_embedding=prefix_embedding,\n",
    "                        head_layer_0_w=head_layer_0_w,\n",
    "                        head_layer_0_bias=head_layer_0_bias,\n",
    "                        head_layer_1_w=head_layer_1_w,\n",
    "                        head_layer_1_bias=head_layer_1_bias,\n",
    "                        head_out_w=head_out_w,\n",
    "                        head_out_bias=head_out_bias)\n",
    "    \n",
    "    \n",
    "#     if 'emb_layer_family_pred_age_level' in name:\n",
    "#         emb_layer_family_pred_age_level = np.round(param.detach().numpy(), 3)\n",
    "        \n",
    "#         print(name)\n",
    "#         print(emb_layer_family_pred_age_level)\n",
    "\n",
    "#     if 'wide.wide_linear.weight' in name:\n",
    "#         print(wide_linear_weight)\n",
    "        \n",
    "        \n",
    "np_file = np.load(\"param.npz\")\n",
    "print(np_file['query_embedding'].shape)\n",
    "print(np_file['query_embedding'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "uuid": "7fc9a933-e493-4754-ac7a-492cea2541cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.443  0.212  0.236 -0.163 -0.278 -0.022  0.075  0.231 -0.211 -0.295\n",
      "  -0.141 -0.128 -0.361  0.392  0.344  0.319 -0.286  0.214 -0.342  0.216\n",
      "   0.367 -0.185 -0.254 -0.286  0.413 -0.328 -0.269 -0.203 -0.141  0.264\n",
      "  -0.067 -0.17  -0.112  0.388 -0.353  0.181  0.142  0.29   0.005  0.213\n",
      "  -0.378  0.38  -0.333  0.382 -0.198 -0.458  0.14   0.408 -0.292 -0.16\n",
      "  -0.157 -0.16  -0.114  0.455 -0.171 -0.048 -0.278  0.226 -0.146 -0.193\n",
      "   0.248  0.334  0.126  0.258  0.196  0.1   -0.43   0.181 -0.23   0.135\n",
      "  -0.354  0.357 -0.153  0.12  -0.207  0.241 -0.26   0.262  0.137  0.271\n",
      "   0.403  0.207  0.213  0.15   0.042  0.167  0.279 -0.393  0.284  0.036\n",
      "   0.328  0.233  0.357 -0.146 -0.184  0.035 -0.447  0.201 -0.188  0.643\n",
      "  -0.118  0.351 -0.231  0.11  -0.248  0.494 -0.294 -0.252  0.284 -0.354\n",
      "   0.159 -0.083  0.216  0.458  0.133 -0.276 -0.224 -0.14  -0.149  0.284\n",
      "  -0.197 -0.199  0.26   0.343 -0.461  0.174  0.298  0.283]]\n"
     ]
    }
   ],
   "source": [
    "# [rows, cols] = np_file['dense_layer_1_bias'].shape\n",
    "\n",
    "print(np_file['head_out_w'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "0e474a0f-367a-459b-abaf-1010f7973efa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
